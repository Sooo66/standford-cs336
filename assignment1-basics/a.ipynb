{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9eed949c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test string: hello 你好啊👋\n",
      "Test bytes: b'hello \\xe4\\xbd\\xa0\\xe5\\xa5\\xbd\\xe5\\x95\\x8a\\xf0\\x9f\\x91\\x8b'\n",
      "Test bytes value: [104, 101, 108, 108, 111, 32, 228, 189, 160, 229, 165, 189, 229, 149, 138, 240, 159, 145, 139]\n"
     ]
    }
   ],
   "source": [
    "test_string = \"hello 你好啊👋\"\n",
    "test_bytes = test_string.encode('utf-8')\n",
    "test_bytes_value = list(test_bytes)\n",
    "print(\"Test string:\", test_string)\n",
    "print(\"Test bytes:\", test_bytes)\n",
    "print(\"Test bytes value:\", test_bytes_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "469eb68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test string: hello 你好啊👋\n",
      "Test bytes: b'\\xff\\xfeh\\x00e\\x00l\\x00l\\x00o\\x00 \\x00`O}YJU=\\xd8K\\xdc'\n",
      "Test bytes value: [255, 254, 104, 0, 101, 0, 108, 0, 108, 0, 111, 0, 32, 0, 96, 79, 125, 89, 74, 85, 61, 216, 75, 220]\n"
     ]
    }
   ],
   "source": [
    "test_string = \"hello 你好啊👋\"\n",
    "test_bytes = test_string.encode('utf-16')\n",
    "test_bytes_value = list(test_bytes)\n",
    "print(\"Test string:\", test_string)\n",
    "print(\"Test bytes:\", test_bytes)\n",
    "print(\"Test bytes value:\", test_bytes_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "596fc38c",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xff in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[33;43mb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\xff\u001b[39;49;00m\u001b[38;5;130;43;01m\\xff\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "b'\\xff\\xff'.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d582d228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(32, 120, 121): 1})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ' xy'.encode('utf-8')\n",
    "from collections import Counter\n",
    "c = Counter()\n",
    "c[tuple(x)] += 1\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ba0ad4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b' xy'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = ' xy'.encode('utf-8')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ab247ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'abc']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'abc'\n",
    "list(tuple([x.encode()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75881cec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b' xy',)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14930c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'\\xe7', b'\\x89', b'\\x9b', b'\\xe5', b'\\x95', b'\\x8a']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = '牛啊'\n",
    "list(tuple([bytes([b]) for b in token.encode('utf-8')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "088ac460",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m x = (\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m = \u001b[32m2\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "x = (1, 2)\n",
    "x[0] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5862220b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(b'a', b'b'): 1, (b'ba', 'a'): 1})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "x = Counter([(b'a', b'b'), (b'ba', 'a')])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c4f0a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((b'a', b'b'), 1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.most_common(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33d699f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 1, 'b': 1, 'c': 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eb5d62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('BA', 'A')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"ZZ\"), (\"BA\", \"A\")]\n",
    "x.sort()\n",
    "max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f137aee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'dsjaidjasjdi',\n",
       " '[CLS]',\n",
       " ' ',\n",
       " '[CLS]',\n",
       " ' asdjiajd',\n",
       " '[SEP]',\n",
       " ' da ',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import regex as re\n",
    "special_tokens = ['[CLS]', '[SEP]']\n",
    "chunk = '[CLS]dsjaidjasjdi[CLS] [CLS] asdjiajd[SEP] da [SEP]'\n",
    "pattern = \"|\".join(f\"({re.escape(tok)})\" for tok in special_tokens)\n",
    "sub_chunks = re.split(pattern, chunk)\n",
    "x = [c for c in sub_chunks if c]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc086852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = b'[CLS]'\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd4862e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello, how ', '<|endoftext|><|endoftext|>', ' are you?', '<|endoftext|>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import regex as re\n",
    "PAT = r\"\"\"'(?:[sdmt]|ll|ve|re)| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    "text = 'Hello, how <|endoftext|><|endoftext|> are you?<|endoftext|>'\n",
    "special_pattern = \"|\".join(re.escape(tok) for tok in special_tokens)\n",
    "split_pattern = f\"({special_pattern})\"\n",
    "\n",
    "# 将文本分割成常规文本和特殊令牌的序列\n",
    "chunks = re.split(split_pattern, text)\n",
    "chunks = [chunk for chunk in chunks if chunk] # 过滤掉可能产生的空字符串\n",
    "\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62303473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "tokenizer = json.load(open('/home/yangmingxuan/standford-cs336/data/owt_train_tokenizer.json', 'r'))\n",
    "vocab, merges = tokenizer['vocab'], tokenizer['merges']\n",
    "# write the vocab and merges to files\n",
    "with open('/home/yangmingxuan/standford-cs336/data/owt_train_vocab.json', 'w') as f:\n",
    "    json.dump(vocab, f, ensure_ascii=False, indent=2)\n",
    "with open('/home/yangmingxuan/standford-cs336/data/owt_train_merges.json', 'w') as f:\n",
    "    json.dump(merges, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ed69069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "tokenizer = json.load(open('/home/yangmingxuan/standford-cs336/data/TinyStoriesV2-GPT4-train-tokenizer.json', 'r'))\n",
    "vocab, merges = tokenizer['vocab'], tokenizer['merges']\n",
    "# write the vocab and merges to files\n",
    "with open('/home/yangmingxuan/standford-cs336/data/ts_train_vocab.json', 'w') as f:\n",
    "    json.dump(vocab, f, ensure_ascii=False, indent=2)\n",
    "with open('/home/yangmingxuan/standford-cs336/data/ts_train_merges.json', 'w') as f:\n",
    "    json.dump(merges, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2468b65b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
